{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oe9vkEvFABbN"
   },
   "source": [
    "[![Roboflow Notebooks](https://ik.imagekit.io/roboflow/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n",
    "\n",
    "# How to Train YOLOv8 Object Detection on a Custom Dataset\n",
    "\n",
    "---\n",
    "\n",
    "[![Roboflow](https://raw.githubusercontent.com/roboflow-ai/notebooks/main/assets/badges/roboflow-blogpost.svg)](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset)\n",
    "[![YouTube](https://badges.aleen42.com/src/youtube.svg)](https://youtu.be/wuZtUMEiKWY)\n",
    "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n",
    "\n",
    "Ultralytics YOLOv8 is the latest version of the YOLO (You Only Look Once) object detection and image segmentation model developed by Ultralytics. The YOLOv8 model is designed to be fast, accurate, and easy to use, making it an excellent choice for a wide range of object detection and image segmentation tasks. It can be trained on large datasets and is capable of running on a variety of hardware platforms, from CPUs to GPUs.\n",
    "\n",
    "## ‚ö†Ô∏è Disclaimer\n",
    "\n",
    "YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "## Accompanying Blog Post\n",
    "\n",
    "We recommend that you follow along in this notebook while reading the blog post on how to train YOLOv8 Object Detection, concurrently.\n",
    "\n",
    "## Pro Tip: Use GPU Acceleration\n",
    "\n",
    "If you are running this notebook in Google Colab, navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`. This will ensure your notebook uses a GPU, which will significantly speed up model training times.\n",
    "\n",
    "## Steps in this Tutorial\n",
    "\n",
    "In this tutorial, we are going to cover:\n",
    "\n",
    "- Before you start\n",
    "- Install YOLOv8\n",
    "- CLI Basics\n",
    "- Inference with Pre-trained COCO Model\n",
    "- Roboflow Universe\n",
    "- Preparing a custom dataset\n",
    "- Custom Training\n",
    "- Validate Custom Model\n",
    "- Inference with Custom Model\n",
    "\n",
    "**Let's begin!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyRdDYkqAKN4"
   },
   "source": [
    "## Before you start\n",
    "\n",
    "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8cDtxLIBHgQ",
    "outputId": "fd9f49a5-1c29-441d-c3e2-b6e452602c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 17 12:36:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.69       Driver Version: 511.69       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   38C    P0    N/A /  N/A |      0MiB /  2048MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     14928    C+G   ...\\Kinect\\KinectService.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CjpPg4mGKc1v",
    "outputId": "0cc05171-8428-4281-9177-14a0aa53a2dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmtya\\OneDrive\\Masa√ºst√º\\Graduation Project\\Cappuccino-Preparing-Robot-Baxter\\object detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C3EO_2zNChu"
   },
   "source": [
    "## Install YOLOv8\n",
    "\n",
    "‚ö†Ô∏è YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **27.01.2023** with version **YOLOv8.0.20**.\n",
    "\n",
    "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
    "\n",
    "YOLOv8 can be installed in two ways‚Ää-‚Ääfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdSMcABDNKW-",
    "outputId": "dbea2a9e-4563-45d7-fffa-1028e51096b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.7.6rc1 torch-1.13.1+cpu CPU\n",
      "Setup complete  (8 CPUs, 15.8 GB RAM, 239.7/254.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# Pip install method (recommended)\n",
    "\n",
    "!pip install ultralytics==8.0.20\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iVvaIYEEPOty"
   },
   "outputs": [],
   "source": [
    "# Git clone method (for development)\n",
    "\n",
    "# %cd {HOME}\n",
    "# !git clone github.com/ultralytics/ultralytics\n",
    "# %cd {HOME}/ultralytics\n",
    "# !pip install -e .\n",
    "\n",
    "# from IPython import display\n",
    "# display.clear_output()\n",
    "\n",
    "# import ultralytics\n",
    "# ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VOEYrlBoP9-E"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnnZSm5OQfPQ"
   },
   "source": [
    "## CLI Basics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K33S7zlkQku0"
   },
   "source": [
    "If you want to train, validate or run inference on models and don't need to make any modifications to the code, using YOLO command line interface is the easiest way to get started. Read more about CLI in [Ultralytics YOLO Docs](https://docs.ultralytics.com/usage/cli/).\n",
    "\n",
    "```\n",
    "yolo task=detect    mode=train    model=yolov8n.yaml      args...\n",
    "          classify       predict        yolov8n-cls.yaml  args...\n",
    "          segment        val            yolov8n-seg.yaml  args...\n",
    "                         export         yolov8n.pt        format=onnx  args...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5RGYA6sPgEd"
   },
   "source": [
    "## Inference with Pre-trained COCO Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT1qD4toTTw0"
   },
   "source": [
    "### üíª CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaE1kLS8R4CV"
   },
   "source": [
    "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDbMt_M6PiXb",
    "outputId": "3c2fd973-0d92-4f5c-dbc4-8800c7de87f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmtya\\OneDrive\\Masa√ºst√º\\Graduation Project\\Cappuccino-Preparing-Robot-Baxter\\object detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
      "\n",
      "  0%|          | 0.00/6.23M [00:00<?, ?B/s]\n",
      "  2%|‚ñè         | 136k/6.23M [00:00<00:05, 1.22MB/s]\n",
      "  6%|‚ñã         | 408k/6.23M [00:00<00:03, 1.99MB/s]\n",
      " 11%|‚ñà         | 712k/6.23M [00:00<00:02, 2.45MB/s]\n",
      " 15%|‚ñà‚ñå        | 960k/6.23M [00:00<00:02, 2.38MB/s]\n",
      " 19%|‚ñà‚ñâ        | 1.17M/6.23M [00:00<00:02, 2.34MB/s]\n",
      " 24%|‚ñà‚ñà‚ñé       | 1.47M/6.23M [00:00<00:01, 2.57MB/s]\n",
      " 28%|‚ñà‚ñà‚ñä       | 1.72M/6.23M [00:00<00:01, 2.41MB/s]\n",
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 2.02M/6.23M [00:00<00:01, 2.58MB/s]\n",
      " 37%|‚ñà‚ñà‚ñà‚ñã      | 2.30M/6.23M [00:00<00:01, 2.67MB/s]\n",
      " 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 2.67M/6.23M [00:01<00:01, 3.02MB/s]\n",
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 2.97M/6.23M [00:01<00:01, 2.46MB/s]\n",
      " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3.28M/6.23M [00:01<00:01, 2.53MB/s]\n",
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3.54M/6.23M [00:01<00:01, 2.48MB/s]\n",
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3.83M/6.23M [00:01<00:00, 2.61MB/s]\n",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4.19M/6.23M [00:01<00:00, 2.84MB/s]\n",
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 4.53M/6.23M [00:01<00:00, 3.03MB/s]\n",
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 4.83M/6.23M [00:01<00:00, 2.60MB/s]\n",
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 5.09M/6.23M [00:02<00:00, 2.12MB/s]\n",
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 5.44M/6.23M [00:02<00:00, 2.45MB/s]\n",
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 5.78M/6.23M [00:02<00:00, 2.68MB/s]\n",
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 6.12M/6.23M [00:02<00:00, 2.91MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:02<00:00, 2.60MB/s]\n",
      "\n",
      "Ultralytics YOLOv8.0.20  Python-3.7.6rc1 torch-1.13.1+cpu CPU\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\cfg\\__init__.py\", line 249, in entrypoint\n",
      "    getattr(model, mode)(verbose=True, **overrides)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 146, in predict\n",
      "    return self.predictor(source=source, stream=stream, verbose=verbose)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 158, in __call__\n",
      "    return list(self.stream_inference(source, model, verbose))  # merge list of Result into one\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 173, in stream_inference\n",
      "    self.setup_source(source)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 110, in setup_source\n",
      "    source, webcam, screenshot, from_img = self.check_source(source)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\", line 250, in check_source\n",
      "    source = check_file(source)  # download\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ultralytics\\yolo\\utils\\checks.py\", line 210, in check_file\n",
      "    if Path(file).is_file() or not file:  # exists\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pathlib.py\", line 1382, in is_file\n",
      "    return S_ISREG(self.stat().st_mode)\n",
      "  File \"C:\\Users\\dmtya\\AppData\\Local\\Programs\\Python\\Python37\\lib\\pathlib.py\", line 1178, in stat\n",
      "    return self._accessor.stat(self)\n",
      "OSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'https:\\\\media.roboflow.com\\\\notebooks\\\\examples\\\\dog.jpeg'\n",
      "Sentry is attempting to send 2 pending error messages\n",
      "Waiting up to 2 seconds\n",
      "Press Ctrl-Break to quit\n"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg' save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "LyopYpK1TQrB",
    "outputId": "287966c3-84c5-4bb4-8163-8911acb4d37a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmtya\\OneDrive\\Masa√ºst√º\\Graduation Project\\Cappuccino-Preparing-Robot-Baxter\\object detection\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/predict/dog.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2576\\3528155452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'{HOME}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'runs/detect/predict/dog.jpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\dmtya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[0;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[1;32m-> 1232\u001b[1;33m                 metadata=metadata)\n\u001b[0m\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dmtya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dmtya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1261\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dmtya\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mreload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    660\u001b[0m         \u001b[1;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/predict/dog.jpeg'"
     ]
    }
   ],
   "source": [
    "%cd {HOME}\n",
    "Image(filename='./dog.jpeg', height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFMBYQtMVL-B"
   },
   "source": [
    "### üêç Python SDK\n",
    "\n",
    "The simplest way of simply using YOLOv8 directly in a Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rx9NWF-sVN6Y",
    "outputId": "f8b8e341-ae74-4b33-92ea-0e0c10a63902"
   },
   "outputs": [],
   "source": [
    "model = YOLO(f'{HOME}/yolov8n.pt')\n",
    "results = model.predict(source='https://media.roboflow.com/notebooks/examples/dog.jpeg', conf=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kAi4PvrItTCf",
    "outputId": "3a1a1c21-be10-437f-aa14-4995d5321789"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HqT2M01K1LUb",
    "outputId": "ac8d0988-8be7-4fec-c62b-2cd8fe9b5371"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gKIwJ5yw1PMb",
    "outputId": "ee27ea55-240f-43fd-d9a3-e8b8a73149fb"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2Xtaekw3271"
   },
   "source": [
    "## Roboflow Universe\n",
    "\n",
    "Need data for your project? Before spending time on annotating, check out Roboflow Universe, a repository of more than 110,000 open-source datasets that you can use in your projects. You'll find datasets containing everything from annotated cracks in concrete to plant images with disease annotations.\n",
    "\n",
    "\n",
    "[![Roboflow Universe](https://ik.imagekit.io/roboflow/notebooks/template/uni-banner-frame.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672878480290)](https://universe.roboflow.com/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JHICVjZbVKn"
   },
   "source": [
    "## Preparing a custom¬†dataset\n",
    "\n",
    "Building a custom dataset can be a painful process. It might take dozens or even hundreds of hours to collect images, label them, and export them in the proper format. Fortunately, Roboflow makes this process as straightforward and fast as possible. Let me show you how!\n",
    "\n",
    "### Step 1: Creating project\n",
    "\n",
    "Before you start, you need to create a Roboflow [account](https://app.roboflow.com/login). Once you do that, you can create a new project in the Roboflow [dashboard](https://app.roboflow.com/). Keep in mind to choose the right project type. In our case, Object Detection.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    width=\"640\"\n",
    "    src=\"https://ik.imagekit.io/roboflow/preparing-custom-dataset-example/creating-project.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672929799852\"\n",
    "  >\n",
    "</div>\n",
    "\n",
    "### Step 2: Uploading images\n",
    "\n",
    "Next, add the data to your newly created project. You can do it via API or through our [web interface](https://docs.roboflow.com/adding-data/object-detection).\n",
    "\n",
    "If you drag and drop a directory with a dataset in a supported format, the Roboflow dashboard will automatically read the images and annotations together. \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    width=\"640\"\n",
    "    src=\"https://ik.imagekit.io/roboflow/preparing-custom-dataset-example/uploading-images.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672929808290\"\n",
    "  >\n",
    "</div>\n",
    "\n",
    "### Step 3: Labeling\n",
    "\n",
    "If you only have images, you can label them in [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    width=\"640\"\n",
    "    src=\"https://user-images.githubusercontent.com/26109316/210901980-04861efd-dfc0-4a01-9373-13a36b5e1df4.gif\"\n",
    "  >\n",
    "</div>\n",
    "\n",
    "### Step 4: Generate new dataset version\n",
    "\n",
    "Now that we have our images and annotations added, we can Generate a Dataset Version. When Generating a Version, you may elect to add preprocessing and augmentations. This step is completely optional, however, it can allow you to significantly improve the robustness of your model.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    width=\"640\"\n",
    "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/generate-new-version.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1673003597834\"\n",
    "  >\n",
    "</div>\n",
    "\n",
    "### Step 5: Exporting dataset\n",
    "\n",
    "Once the dataset version is generated, we have a hosted dataset we can load directly into our notebook for easy training. Click `Export` and select the `YOLO v5 PyTorch` dataset format.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    width=\"640\"\n",
    "    src=\"https://ik.imagekit.io/roboflow/preparing-custom-dataset-example/export.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672943313709\"\n",
    "  >\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSd93ZJzZZKt",
    "outputId": "40c99cf3-2dc1-4fdb-e619-6338ba33f9b6"
   },
   "outputs": [],
   "source": [
    "!mkdir {HOME}/datasets\n",
    "%cd {HOME}/datasets\n",
    "\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"o03639Rjl20zIjHrKB4v\")\n",
    "project = rf.workspace(\"boazii-university\").project(\"cup_place_finder\")\n",
    "dataset = project.version(1).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUjFBKKqXa-u"
   },
   "source": [
    "## Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2YkphuiaE7_",
    "outputId": "a7414341-df8a-4ef6-e772-383827b481fe"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MScstfHhArr",
    "outputId": "210f2b1e-aea6-464b-d69e-319c473338a4"
   },
   "outputs": [],
   "source": [
    "!ls {HOME}/runs/detect/train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "id": "_J35i8Ofhjxa",
    "outputId": "3584e96f-5a55-4391-c51f-3acf53f80cd9"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "A-urTWUkhRmn",
    "outputId": "836e9053-7035-48ba-ef10-9f7155a329de"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "HI4nADCCj3F5",
    "outputId": "ad7f1e75-222c-4097-ee6a-edcff68ff723"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ODk1VTlevxn"
   },
   "source": [
    "## Validate Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpyuwrNlXc1P",
    "outputId": "f0bb32ee-5da7-4249-f6e8-bb19ef860b4d"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4eASbcWkQBq"
   },
   "source": [
    "## Inference with Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wjc1ctZykYuf",
    "outputId": "95967de2-7d16-414a-dfc5-7c8eb38065e6"
   },
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.25 source={dataset.location}/test/images save=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEYIo95n-I0S"
   },
   "source": [
    "**NOTE:** Let's take a look at few results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jbVjEtPAkz3j",
    "outputId": "94a5d40d-62e8-4347-bd4b-183aae9e002a"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for image_path in glob.glob(f'{HOME}/runs/detect/predict3/*.jpg')[:3]:\n",
    "      display(Image(filename=image_path, width=600))\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0tsVilOCPyq"
   },
   "source": [
    "## Deploy model on Roboflow\n",
    "\n",
    "Once you have finished training your YOLOv8 model, you‚Äôll have a set of trained weights ready for use. These weights will be in the `/runs/detect/train/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
    "\n",
    "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) now supports uploading YOLOv8 weights.\n",
    "\n",
    "To upload model weights, add the following code to the ‚ÄúInference with Custom Model‚Äù section in the aforementioned notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EhBAJ2gCPZh",
    "outputId": "259decf5-1c4e-4011-a208-a2498acc30ca"
   },
   "outputs": [],
   "source": [
    "project.version(dataset.version).deploy(model_type=\"yolov8\", model_path=f\"{HOME}/runs/detect/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5kOhjkmcV1l"
   },
   "outputs": [],
   "source": [
    "#While your deployment is processing, checkout the deployment docs to take your model to most destinations https://docs.roboflow.com/inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I4bpUIibcV1l"
   },
   "outputs": [],
   "source": [
    "#Run inference on your model on a persistant, auto-scaling, cloud API\n",
    "\n",
    "#load model\n",
    "model = project.version(dataset.version).model\n",
    "\n",
    "#choose random test set image\n",
    "import os, random\n",
    "test_set_loc = dataset.location + \"/test/images/\"\n",
    "random_test_image = random.choice(os.listdir(test_set_loc))\n",
    "print(\"running inference on \" + random_test_image)\n",
    "\n",
    "pred = model.predict(test_set_loc + random_test_image, confidence=40, overlap=30).json()\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovQgOj_xSNDg"
   },
   "source": [
    "## üèÜ Congratulations\n",
    "\n",
    "### Learning Resources\n",
    "\n",
    "Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:\n",
    "\n",
    "- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.\n",
    "- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.\n",
    "- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.\n",
    "- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.\n",
    "\n",
    "### Convert data formats\n",
    "\n",
    "Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.\n",
    "\n",
    "### Connect computer vision to your project logic\n",
    "\n",
    "[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
