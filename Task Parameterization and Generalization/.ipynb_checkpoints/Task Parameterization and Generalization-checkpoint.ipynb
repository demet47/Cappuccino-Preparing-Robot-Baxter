{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import TimeDistributed,Dense,Activation,Layer,Input,Average,Concatenate,Flatten,Lambda\n",
    "from keras.optimizers import Adam\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import csv\n",
    "import data_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_array(csv_file_name):\n",
    "    data = []\n",
    "    flag = True\n",
    "    with open(csv_file_name, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for row in csv_reader:\n",
    "            if(flag):\n",
    "                flag = False\n",
    "                continue\n",
    "            data.append(row)\n",
    "    \n",
    "    data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colors/Desktop/CNMP/Example Experiments/Task Parameterization and Generalization/data_format.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data), max_size\n"
     ]
    }
   ],
   "source": [
    "d_N = 2\n",
    "n_max=2 # maximum number of observations that can be used during the training process\n",
    "a,b,c,d = data_format.data_per_trajectory('/home/colors/Desktop/Cappuccino-Preparing-Robot-Baxter/carry_data/train1', True)\n",
    "train_joints = np.array(a)\n",
    "train_n = np.array(b)\n",
    "train_t = np.array(c)  \n",
    "train_p = np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 3866)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_joints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3866, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_sample():\n",
    "    observation = np.zeros((1,n_max,9))\n",
    "    observation_flag = np.zeros((1,1,n_max))\n",
    "    target = np.zeros((1,1,3)) # t, ob_p, w_p  \n",
    "    gamma = random.randint(0,d_N-1)\n",
    "    ob_p = train_p[gamma,0]\n",
    "    w_p = train_p[gamma,1]\n",
    "    obs_n = random.randint(1,n_max)\n",
    "    \n",
    "    perm = np.random.permutation(train_n[gamma])\n",
    "    \n",
    "    for i in range(obs_n):\n",
    "        observation[0,i] = [train_t[gamma,perm[i]],\n",
    "                            (ob_p+1), # 0,1,2 -> 1/3,2/3,1\n",
    "                            (w_p+1), # 0,1,2,3 -> 1/4,2/4,3/4,1\n",
    "                            train_joints[gamma,0,perm[i]],\n",
    "                            train_joints[gamma,1,perm[i]],\n",
    "                            train_joints[gamma,2,perm[i]],\n",
    "                            train_joints[gamma,3,perm[i]],\n",
    "                            train_joints[gamma,4,perm[i]],\n",
    "                            train_joints[gamma,5,perm[i]],\n",
    "                           ]\n",
    "        observation_flag[0,0,i] = 1./obs_n\n",
    "    target[0,0] = [train_t[gamma,perm[obs_n]], (ob_p+1)/3., (w_p+1)/4.]\n",
    "    return [observation,observation_flag,target], \\\n",
    "            [[[[train_joints[gamma,0,perm[obs_n]],\n",
    "                train_joints[gamma,1,perm[obs_n]],\n",
    "                train_joints[gamma,2,perm[obs_n]],\n",
    "                train_joints[gamma,3,perm[obs_n]],\n",
    "                train_joints[gamma,4,perm[obs_n]],\n",
    "                train_joints[gamma,5,perm[obs_n]],\n",
    "                0.,0.,0.,0.,0.,0.]]]],gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_predictions(gamma=1): \n",
    "    ob_p=train_p[gamma,0]\n",
    "    w_p=train_p[gamma,1]\n",
    "    prediction = np.zeros((6,train_n[gamma]))\n",
    "    prediction_std = np.zeros((6,train_n[gamma]))\n",
    "    observation = np.zeros((1,n_max,9))\n",
    "    observation_flag = np.zeros((1,1,n_max))\n",
    "    target = np.zeros((1,1,3))\n",
    "    observation[0,0] = [0,(ob_p+1)/3.,(w_p+1)/4.,\n",
    "                        train_joints[gamma,0,0],\n",
    "                        train_joints[gamma,1,0],\n",
    "                        train_joints[gamma,2,0],\n",
    "                        train_joints[gamma,3,0],\n",
    "                        train_joints[gamma,4,0],\n",
    "                        train_joints[gamma,5,0]]\n",
    "    observation_flag[0,0,0] = 1.\n",
    "    joint_names = ['Base Joint (rad)','Shoulder Joint (rad)','Elbow Joint (rad)','Wrist1 Joint (rad)','Wrist2 Joint (rad)','Wrist3 Joint (rad)',]        \n",
    "    for i in range(train_n[gamma]):\n",
    "        target[0,0] = [train_t[gamma,i],(ob_p+1)/3.,(w_p+1)/4.]\n",
    "        p = model.predict([observation,observation_flag,target])[0][0]\n",
    "        prediction[:,i] = p[:6]\n",
    "        for j in range(6):\n",
    "            prediction_std[j,i] = math.log(1+math.exp(p[6+j]))\n",
    "    for joint in range(6):\n",
    "        fig = plt.figure(figsize=(5,5))\n",
    "        plt.title(joint_names[joint])\n",
    "        if joint == 4:\n",
    "            plt.ylim(-1.35,-1.75)\n",
    "        for i in range(d_N):\n",
    "            plt.plot(range(train_n[i]),train_joints[i,joint,:train_n[i]])\n",
    "        plt.plot(range(train_n[gamma]),prediction[joint,:train_n[gamma]],color='red')\n",
    "        plt.errorbar(range(train_n[gamma]),prediction[joint,:train_n[gamma]],yerr=prediction_std[2,:train_n[gamma]],color = 'red',alpha=0.1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    mean, log_sigma = tf.split(y_pred, 2, axis=-1)\n",
    "    y_target, temp =tf.split(y_true,2,axis=-1)\n",
    "    sigma = tf.nn.softplus(log_sigma)\n",
    "    dist = tfp.distributions.MultivariateNormalDiag(loc=mean, scale_diag=sigma)\n",
    "    loss = -tf.reduce_mean(dist.log_prob(y_target))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 2, 9)]       0           []                               \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDistri  (None, 2, 128)      1280        ['input_4[0][0]']                \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 2, 128)      16512       ['time_distributed_5[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 2, 128)      16512       ['time_distributed_6[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_8 (TimeDistri  (None, 2, 128)      16512       ['time_distributed_7[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " time_distributed_9 (TimeDistri  (None, 2, 128)      16512       ['time_distributed_8[0][0]']     \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)              (None, 1, 128)       0           ['input_5[0][0]',                \n",
      "                                                                  'time_distributed_9[0][0]']     \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1, 3)]       0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1, 131)       0           ['lambda_1[0][0]',               \n",
      "                                                                  'input_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1, 128)       16896       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1, 128)       16512       ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1, 128)       16512       ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1, 128)       16512       ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1, 12)        1548        ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 135,308\n",
      "Trainable params: 135,308\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/colors/.local/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "observation_layer = Input(shape=(n_max,9))\n",
    "observation_flag_layer=Input(shape=(1,n_max)) \n",
    "observation_encoded = TimeDistributed(Dense(128, activation='relu'))(observation_layer)\n",
    "observation_encoded = TimeDistributed(Dense(128, activation='relu'))(observation_encoded)\n",
    "observation_encoded = TimeDistributed(Dense(128, activation='relu'))(observation_encoded)\n",
    "observation_encoded = TimeDistributed(Dense(128, activation='relu'))(observation_encoded)\n",
    "observation_encoded = TimeDistributed(Dense(128))(observation_encoded)\n",
    "matmul_layer=Lambda(lambda x:(tf.matmul(x[0],x[1])), output_shape =(1,128))\n",
    "representation=matmul_layer([observation_flag_layer,observation_encoded])\n",
    "target_layer = Input(shape=(1,3))\n",
    "query_net_input = Concatenate(axis=2)([representation, target_layer])\n",
    "query = Dense(128, activation='relu')(query_net_input)\n",
    "query = Dense(128, activation='relu')(query)\n",
    "query = Dense(128, activation='relu')(query)\n",
    "query = Dense(128, activation='relu')(query)\n",
    "output_layer = Dense(12)(query)\n",
    "model = Model(inputs=[observation_layer,observation_flag_layer,target_layer],outputs=output_layer)\n",
    "model.compile(optimizer = Adam(lr = 1e-4),loss=custom_loss)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m max_iterations\u001b[39m=\u001b[39m\u001b[39m1000000\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iterations):\n\u001b[0;32m----> 4\u001b[0m     inp,out,gamma \u001b[39m=\u001b[39m get_train_sample()\n\u001b[1;32m      5\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(out)\n\u001b[1;32m      6\u001b[0m     data \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(inp,out,batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m, in \u001b[0;36mget_train_sample\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m perm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mpermutation(train_n[gamma])\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(obs_n):\n\u001b[0;32m---> 13\u001b[0m     observation[\u001b[39m0\u001b[39;49m,i] \u001b[39m=\u001b[39m [train_t[gamma,perm[i]],\n\u001b[1;32m     14\u001b[0m                         (ob_p\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m# 0,1,2 -> 1/3,2/3,1\u001b[39;00m\n\u001b[1;32m     15\u001b[0m                         (w_p\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m), \u001b[39m# 0,1,2,3 -> 1/4,2/4,3/4,1\u001b[39;00m\n\u001b[1;32m     16\u001b[0m                         train_joints[gamma,\u001b[39m0\u001b[39m,perm[i]],\n\u001b[1;32m     17\u001b[0m                         train_joints[gamma,\u001b[39m1\u001b[39m,perm[i]],\n\u001b[1;32m     18\u001b[0m                         train_joints[gamma,\u001b[39m2\u001b[39m,perm[i]],\n\u001b[1;32m     19\u001b[0m                         train_joints[gamma,\u001b[39m3\u001b[39m,perm[i]],\n\u001b[1;32m     20\u001b[0m                         train_joints[gamma,\u001b[39m4\u001b[39m,perm[i]],\n\u001b[1;32m     21\u001b[0m                         train_joints[gamma,\u001b[39m5\u001b[39m,perm[i]],\n\u001b[1;32m     22\u001b[0m                        ]\n\u001b[1;32m     23\u001b[0m     observation_flag[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,i] \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m\u001b[39m/\u001b[39mobs_n\n\u001b[1;32m     24\u001b[0m target[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m [train_t[gamma,perm[obs_n]], (ob_p\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m3.\u001b[39m, (w_p\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m/\u001b[39m\u001b[39m4.\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 1."
     ]
    }
   ],
   "source": [
    "train_loss = np.zeros(2000)\n",
    "max_iterations=1000000\n",
    "for step in range(max_iterations):\n",
    "    inp,out,gamma = get_train_sample()\n",
    "    out = np.array(out)\n",
    "    data = model.fit(inp,out,batch_size=1,verbose=0)\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        train_loss[step//1000] = data.history['loss'][0]\n",
    "    if step % 10000 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(pl.gcf())\n",
    "        print( 'step:', step)\n",
    "        print( 'loss:', data.history['loss'][0])\n",
    "        plt.title('Train Loss')\n",
    "        plt.plot(range(2000),train_loss)\n",
    "        plt.show()\n",
    "        mean_loss = np.zeros((100))\n",
    "        for i in range(100):\n",
    "            mean_loss[i] = np.mean(train_loss[i*20:(i+1)*20])\n",
    "        fig = plt.figure()\n",
    "        plt.title('Train Loss (Smoothed)')\n",
    "        plt.plot(range(100),mean_loss)\n",
    "        plt.show()\n",
    "        plt_predictions(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
